{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Iris Dataset Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T14:37:28.833792Z",
     "start_time": "2020-10-29T14:37:25.473738Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "from itertools import compress\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dtreeviz.trees import dtreeviz\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are from the [UCI ML repository](https://archive.ics.uci.edu/ml/datasets/wine+quality).\n",
    "<br>\n",
    "<br>\n",
    "They contain information about chemical and sensory characteristics of wines as well as a rating of the quality of the wine.\n",
    "<br>\n",
    "<br>\n",
    "I'm only going to use this dataset to provide an example of how to construct a randomized search to tune hyperparameters using sci-kit learn's `Pipeline` function. There is much more you could do with this dataset, and if you were actually going to construct a proper model you'd want to do EDA, data cleaning, and do some class balancing of course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T14:37:28.925254Z",
     "start_time": "2020-10-29T14:37:28.847619Z"
    }
   },
   "outputs": [],
   "source": [
    "## red and white wine are stored in separate csvs\n",
    "red_wine = pd.read_csv('winequality-red.csv', sep=';')\n",
    "white_wine = pd.read_csv('winequality-white.csv', sep=';')\n",
    "## concatenate into single df\n",
    "wines = pd.concat([red_wine,white_wine])\n",
    "## look at data\n",
    "wines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class label column is the quality' column. It's currently an ordinal multiclass label (quality rating between 0-10 with 0 being worst 10 being best). For simplicity I'm just going to turn this into a binary class label with all values less than or equal to five categorized as 'bad' quality and anything with a rating higher than five as 'good' quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T14:37:31.298985Z",
     "start_time": "2020-10-29T14:37:31.281402Z"
    }
   },
   "outputs": [],
   "source": [
    "## create new binary class labels\n",
    "wines['quality_category'] = np.where(wines.quality<=5, 'bad', 'good')\n",
    "## drop the old labels\n",
    "wines.drop(['quality'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T14:37:32.532983Z",
     "start_time": "2020-10-29T14:37:32.514664Z"
    }
   },
   "outputs": [],
   "source": [
    "## features\n",
    "X = wines.iloc[:,:-1]\n",
    "## label\n",
    "y = wines.quality_category\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Pipeline\n",
    "\n",
    "Basic pipeline steps with hyperparameter tuning are:<br>\n",
    "<br>\n",
    "1) define the models to fit\n",
    "\n",
    "2) define the hyperparameters to search over for each model\n",
    "\n",
    "3) put together using the `Pipeline` function\n",
    "\n",
    "4) compare results of all fitted models with tuned hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Define models\n",
    "\n",
    "Since we are talking about decision trees, random forests, and XGBoost today we will fit these three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T14:37:35.431844Z",
     "start_time": "2020-10-29T14:37:35.426701Z"
    }
   },
   "outputs": [],
   "source": [
    "## define the models to fit\n",
    "base_models = [DecisionTreeClassifier(random_state=42),\n",
    "               RandomForestClassifier(random_state=42),\n",
    "               ExtraTreesClassifier(random_state=42),\n",
    "               XGBClassifier(random_state=42)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Define the hyperparameters\n",
    "\n",
    "As you know, each model has many hyperparameters you can tune. There are also a couple of options for how to tune the hyperparameters - grid search and randomized search.\n",
    "<br>\n",
    "<br>\n",
    "With grid search, the user specifically defines which values the hyperparameters will take, with random search, the user defines a random distribution for the search to pass over and the user can define what distribution the hyperparameters should take. \n",
    "<br>\n",
    "<br>\n",
    "In order to feed the parameters into the pipeline, they need to have the model name as a prefix before the hyperparameter name, separated by a dunder (e.g. `clf__criterion`)\n",
    "<br>\n",
    "<br>\n",
    "If you don't remember what hyperparameters a model has a quick way to check is `get_params`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T14:37:38.228744Z",
     "start_time": "2020-10-29T14:37:38.221925Z"
    }
   },
   "outputs": [],
   "source": [
    "## check hyperparameters of a model\n",
    "list(DecisionTreeClassifier().get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T15:12:07.997424Z",
     "start_time": "2020-10-29T15:12:07.952922Z"
    }
   },
   "outputs": [],
   "source": [
    "# define models to test:\n",
    "check_params_dtree = {'clf__criterion':['gini', 'entropy'],\n",
    "                   'clf__max_features': truncnorm(a=0, b=1, loc=0.25, scale=0.1),\n",
    "                   'clf__min_samples_split': uniform(0.01, 0.199),\n",
    "                   'clf__max_depth':randint(1,10)}\n",
    "\n",
    "check_params_rf = {'clf__criterion':['gini', 'entropy'],\n",
    "                   'clf__n_estimators': randint(50,500),\n",
    "                   'clf__max_features': truncnorm(a=0, b=1, loc=0.25, scale=0.1),\n",
    "                   'clf__min_samples_split': randint(2,5),\n",
    "                   'clf__max_depth':randint(3,20)}\n",
    "\n",
    "check_params_et = {'clf__criterion':['gini', 'entropy'],\n",
    "                   'clf__n_estimators': randint(50,500),\n",
    "                   'clf__max_features': truncnorm(a=0, b=1, loc=0.25, scale=0.1),\n",
    "                   'clf__min_samples_split': randint(2,5),\n",
    "                   'clf__max_depth':randint(3,20)}\n",
    "\n",
    "check_params_xgb = {'clf__max_depth':randint(2,8),\n",
    "                    'clf__learning_rate':uniform(0.1,0.3),\n",
    "                    'clf__min_child_weight':uniform(1,10),\n",
    "                    'clf__reg_lambda':uniform(0.1,3)\n",
    "                   }\n",
    "\n",
    "## save parameter spaces in a list\n",
    "check_params = [check_params_dtree, check_params_rf, check_params_et, check_params_xgb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Put together in the pipeline function\n",
    "\n",
    "The pipeline function can have many more steps than what is presented here. Each step should be given a name (e.g. `('sc1', StandardScaler())`). You can put all sorts of stuff in the pipeline, but here I just put the scaling function because it was simple and all of the datasets features are numeric. I don't know if the data actually need this part or if this is the best scaling factor to fit but it's just an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T15:12:11.877242Z",
     "start_time": "2020-10-29T15:12:11.871127Z"
    }
   },
   "outputs": [],
   "source": [
    "def modelFit(clf, params, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"A model to fit the pipeline for a predefined model (clf) using a randomized search\n",
    "    cross validation to tune the hyperparameters (params:dict of predefined hyperparams to search).\n",
    "    Returns the model and a classification report of the model\"\"\"\n",
    "    \n",
    "    pipe = Pipeline(steps=[('sc1', StandardScaler()),\n",
    "                          ('clf', clf)])\n",
    "    \n",
    "    random_search = RandomizedSearchCV(pipe,\n",
    "                                      params,\n",
    "                                      n_iter=100,\n",
    "                                      cv=5,\n",
    "                                      random_state=42)\n",
    "    \n",
    "    model_out = random_search.fit(X_train, y_train)\n",
    "    \n",
    "    y_true, y_pred = y_test, model_out.predict(X_test)\n",
    "    \n",
    "    classification_rep = classification_report(y_true, y_pred)\n",
    "    \n",
    "    return model_out, classification_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Fit and compare the models\n",
    "\n",
    "Now we can put it all together and compare our models with the tuned hyperparameters using the classification reports for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T15:34:20.081730Z",
     "start_time": "2020-10-29T15:12:14.918592Z"
    }
   },
   "outputs": [],
   "source": [
    "### empty spaces to save the models and classification reports\n",
    "fitted_models = []\n",
    "classification_reps = []\n",
    "\n",
    "## run the model for each respective pair of models and hyperparameter dicts\n",
    "for mod, param in zip(base_models, check_params):\n",
    "    one_mod, one_classification = modelFit(mod, param, X_train, y_train, X_test, y_test)\n",
    "    fitted_models.append(one_mod)\n",
    "    classification_reps.append(one_classification)\n",
    "\n",
    "## print the classification reports    \n",
    "[print(x) for x in classification_reps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the classification report you can see that the, based on the F1 score, the XGBoost model fits the best. However, remember that we didn't clean or balance these data...so, don't draw any conclusions from this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Visualization Examples\n",
    "<br>\n",
    "\n",
    "### For funsies\n",
    "\n",
    "<br>\n",
    "If your data has a lot of features, especially a lot of numeric features, it can be too unweildly to visualize a tree. But if your n features is relatively small you can make a neat visualization.\n",
    "<br>\n",
    "<br>\n",
    "The wine dataset is a little much for this visualization, but the comparitively simple iris dataset provides a nice example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T13:57:49.322053Z",
     "start_time": "2020-10-29T13:57:49.290889Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data and split into x, y\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Fit the classifier with default hyper-parameters just to do this simply and quickly\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "model = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One visualization for decision trees is available as the `plot_tree` function in sci-kit learn. It shows all the leaves and nodes of a fitted tree and prints the split criteria (e.g. petal length <= 4.85), the number of samples available for the split and the the gini index of the leaf (or entropy depending on how you set up your model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T13:57:50.525495Z",
     "start_time": "2020-10-29T13:57:49.334750Z"
    }
   },
   "outputs": [],
   "source": [
    "## set plotting area\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "\n",
    "## plot the fitted tree\n",
    "vis_tree = tree.plot_tree(clf, \n",
    "                   feature_names=iris.feature_names,  \n",
    "                   class_names=iris.target_names,\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another cool way to visualize a tree is using the dtreeviz package (installation instructions [here](https://github.com/parrt/dtreeviz) -- the graphviz dependency can be iffy so follow their installation instructions carefully). The dtreeviz shows the distribution of samples within each class for each split as well as the split criteria and the number of samples in each terminal leaf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T13:59:44.092701Z",
     "start_time": "2020-10-29T13:59:40.520696Z"
    }
   },
   "outputs": [],
   "source": [
    "viz = dtreeviz(clf, X, y,\n",
    "                target_name=\"target\",\n",
    "                feature_names=iris.feature_names,\n",
    "                class_names=list(iris.target_names),\n",
    "                scale = 1.3)\n",
    "viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope any of this code comes in useful to you in the future!\n",
    "\n",
    "Here are some useful blogs and links I referenced when making this notebook\n",
    "\n",
    "- [the dtreeviz git](https://github.com/parrt/dtreeviz)\n",
    "- [dtreeviz examples in colab](https://colab.research.google.com/github/parrt/dtreeviz/blob/master/notebooks/examples.ipynb#scrollTo=KTpQ2_t-WLZr)\n",
    "- [4 ways to visualize a tree](https://mljar.com/blog/visualize-decision-tree/)\n",
    "- [blog on randomized parameter search](https://jamesrledoux.com/code/randomized_parameter_search)\n",
    "- [sci-kit learn doc on Pipeline with good examples](https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html)\n",
    "- [hyperparameter tuning with pipelines](https://medium.com/@kocur4d/hyper-parameter-tuning-with-pipelines-5310aff069d6)\n",
    "- [this short but sweet kaggle notebook on xgboost](https://www.kaggle.com/justindeed/iris-with-xgboost-and-gridsearchcv)\n",
    "- [math behind decision trees explained with an example](https://towardsdatascience.com/decision-tree-in-python-b433ae57fb93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
